model:
  hyperparameters:
    batch_size: 128 # Batch size during training
    # Size of z latent vector (i.e. size of generator input)
    nz: 100
    # Size of feature maps in generator
    ngf: 64
    # Size of feature maps in discriminator
    ndf: 64
    # Number of training epochs
    num_epochs: 2  # 5
    # Learning rate for optimizers
    lr: 0.0002
    # Beta1 hyperparam for Adam optimizers
    beta1: 0.5
  infra:
    ngpu: 0 # Number of GPUs available. Use 0 for CPU mode.