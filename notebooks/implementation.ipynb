{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from dcgan.utils.config import read_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config(\"./../config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa141030090>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Root directory for dataset\n",
    "# dataroot = \"data/celeba\"\n",
    "\n",
    "# # Number of workers for dataloader\n",
    "# workers = 2\n",
    "\n",
    "# # Batch size during training\n",
    "# batch_size = 128\n",
    "\n",
    "# # Spatial size of training images. All images will be resized to this\n",
    "# #   size using a transformer.\n",
    "# image_size = 64\n",
    "\n",
    "# # Number of channels in the training images. For color images this is 3\n",
    "# nc = 3\n",
    "\n",
    "# # Size of z latent vector (i.e. size of generator input)\n",
    "# nz = 100\n",
    "\n",
    "# # Size of feature maps in generator\n",
    "# ngf = 64\n",
    "\n",
    "# # Size of feature maps in discriminator\n",
    "# ndf = 64\n",
    "\n",
    "# # Number of training epochs\n",
    "# num_epochs = 5\n",
    "\n",
    "# # Learning rate for optimizers\n",
    "# lr = 0.0002\n",
    "\n",
    "# # Beta1 hyperparam for Adam optimizers\n",
    "# beta1 = 0.5\n",
    "\n",
    "# # Number of GPUs available. Use 0 for CPU mode.\n",
    "# ngpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=config.data.dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(config.data.image_size),\n",
    "                               transforms.CenterCrop(config.data.image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=config.model.hyperparameters.batch_size,\n",
    "                                         shuffle=True, num_workers=config.data.workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and config.model.hyperparameters.ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "142b32c270948be28067515f4b49697dfadb24c7366781e2efb564df567335db"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
